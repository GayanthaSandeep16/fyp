import sys
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score
from imblearn.over_sampling import SMOTE
import pickle
import logging

# Set up logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# Load data
csv_path = sys.argv[1]
logging.info("Loading data...")
df = pd.read_csv(csv_path)

# Verify that the 'target' column exists
if 'target' not in df.columns:
    raise ValueError("CSV file does not contain a 'target' column")

# Log class distribution
logging.info("Class distribution:")
logging.info(df['target'].value_counts())

# The CSV generated by dataToCsvString has standardized columns: 'gender', 'age', 'bmi', 'hba1c', 'glucose', 'target'
# Check if 'glucose' is present to determine which features to use
if 'glucose' in df.columns:
    logging.info("Processing dataset with glucose column...")
    X = df[['gender', 'age', 'bmi', 'hba1c', 'glucose']].copy()
else:
    logging.info("Processing dataset without glucose column...")
    X = df[['gender', 'age', 'bmi', 'hba1c']].copy()

# Target variable is always 'target' in the CSV
y = df['target']

# Ensure all features are numeric
X = X.apply(pd.to_numeric, errors='coerce')

# Handle missing values in features
X = X.fillna(X.mean(numeric_only=True))

# Check for any remaining NaN in X
if X.isna().any().any():
    logging.warning("Features still contain NaN after filling with mean. Replacing with 0...")
    X = X.fillna(0)

# Ensure y is numeric and handle missing values
y = pd.to_numeric(y, errors='coerce')
if y.isna().any():
    logging.warning("Target contains NaN. Dropping rows with NaN in target...")
    valid_indices = y.notna()
    X = X[valid_indices]
    y = y[valid_indices]

# Check if the dataset is empty after cleaning
if len(X) == 0:
    raise ValueError("Dataset is empty after cleaning. No valid rows remain with a non-NaN target.")

# Subsample the data for faster processing (optional, comment out for full dataset)
logging.info("Subsampling data for faster processing...")
sample_size = 20000  # Adjust this as needed
if len(X) > sample_size:
    X, _, y, _ = train_test_split(X, y, train_size=sample_size, stratify=y, random_state=42)
    logging.info(f"Subsampled to {len(X)} rows")

# Apply SMOTE to handle class imbalance
logging.info("Applying SMOTE...")
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X, y)

# Log new class distribution after SMOTE
logging.info("Class distribution after SMOTE:")
logging.info(pd.Series(y_resampled).value_counts())

# Split and scale
logging.info("Splitting and scaling data...")
X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)

# Check for variance in features to avoid scaling issues
if (X_train.std() == 0).any():
    logging.warning("Some features have zero variance. Adding small noise to avoid scaling issues...")
    X_train += np.random.normal(0, 1e-5, X_train.shape)
    X_test += np.random.normal(0, 1e-5, X_test.shape)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Define Random Forest with simplified hyperparameter tuning
logging.info("Training Random Forest with simplified hyperparameter tuning...")
rf = RandomForestClassifier(random_state=42, class_weight="balanced")
param_grid = {
    'n_estimators': [100],  # Reduced to 1 option
    'max_depth': [10, None],  # Reduced to 2 options
    'min_samples_split': [2],  # Reduced to 1 option
    'min_samples_leaf': [1]  # Reduced to 1 option
}
grid_search = GridSearchCV(rf, param_grid, cv=3, scoring='f1', n_jobs=-1, verbose=1)
grid_search.fit(X_train_scaled, y_train)

# Best model
best_rf = grid_search.best_estimator_
logging.info("Best hyperparameters: %s", grid_search.best_params_)

# Predict and evaluate
logging.info("Evaluating model...")
y_pred = best_rf.predict(X_test_scaled)

# Metrics
accuracy = accuracy_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred, average='binary')
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)

print(f"Accuracy: {accuracy:.4f}")
print(f"F1 Score: {f1:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")

# Save model and scaler
logging.info("Saving model and scaler...")
with open("rf_model.pkl", "wb") as f:
    pickle.dump(best_rf, f)
with open("scaler.pkl", "wb") as f:
    pickle.dump(scaler, f)

logging.info("Training completed successfully!")